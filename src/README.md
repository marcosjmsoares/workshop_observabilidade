### **README Atualizado com Coment√°rios sobre os Pontos em Destaque**

---

# **ETL Pipeline com Tracing e Banco de Dados PostgreSQL**

Este projeto implementa um pipeline ETL (Extract, Transform, Load) com instrumenta√ß√£o de tracing usando **Logfire** e armazenamento em um banco de dados PostgreSQL remoto. O objetivo √© demonstrar como integrar spans para monitorar o desempenho e acompanhar cada etapa do pipeline.

---

## **Destaques do C√≥digo**

### 1. **Tracing com Spans**
- O uso de spans no **Logfire** permite monitorar o tempo de execu√ß√£o de cada etapa do pipeline.
- Exemplos no c√≥digo:
  - **Etapa de Extra√ß√£o**:
    ```python
    with logfire.span("Fazendo a requisi√ß√£o para obter o valor do Bitcoin"):
        response = requests.get(url=URL)
    ```
    - Este span mede o tempo para realizar a requisi√ß√£o HTTP.
  - **Etapa de Transforma√ß√£o**:
    ```python
    with logfire.span("Validando os dados com Pydantic"):
        validated_data = ApiResponse(**data)
    ```
    - Este span mede o tempo para validar os dados com o modelo **Pydantic**.
  - **Etapa de Carregamento**:
    ```python
    with logfire.span("Carregando os dados no banco de dados PostgreSQL"):
        session.add(bitcoin_entry)
        session.commit()
    ```
    - Este span mede o tempo para salvar os dados no banco PostgreSQL usando SQLAlchemy.

### 2. **Logs Detalhados**
- O **Logfire** √© usado para gerar logs ricos com contexto adicional. Exemplos incluem:
  - Mensagem de sucesso na conex√£o:
    ```python
    logfire.info("Conex√£o bem-sucedida com o banco PostgreSQL.")
    ```
  - Dados inseridos no banco:
    ```python
    logfire.info(
        "Dado inserido no banco: {amount} {base}/{currency} em {timestamp}",
        amount=bitcoin_entry.amount,
        base=bitcoin_entry.base,
        currency=bitcoin_entry.currency,
        timestamp=bitcoin_entry.timestamp,
    )
    ```

### 3. **Monitoramento do Pipeline Completo**
- Um span envolve a execu√ß√£o completa do pipeline:
  ```python
  with logfire.span("Execu√ß√£o completa do pipeline ETL"):
      raw_data = extract()
      transformed_data = transform(raw_data)
      load(transformed_data)
  ```
  - Ele registra quanto tempo o pipeline completo leva para ser executado.

### 4. **Loop Cont√≠nuo**
- O pipeline √© executado em um loop cont√≠nuo com uma pausa de 10 segundos entre as execu√ß√µes:
  ```python
  while True:
      with logfire.span("Execu√ß√£o completa do pipeline ETL"):
          raw_data = extract()
          transformed_data = transform(raw_data)
          load(transformed_data)
          logfire.info("Pipeline conclu√≠do. Aguardando 10 segundos antes de repetir.")
      sleep(10)
  ```
- √â poss√≠vel interromper o loop pressionando `Ctrl+C`, capturado pelo seguinte bloco:
  ```python
  except KeyboardInterrupt:
      logfire.info("Execu√ß√£o do pipeline interrompida pelo usu√°rio.")
  ```

---

## **Passos para Rodar o Projeto**

1. **Clonar o Reposit√≥rio**
   ```bash
   git clone https://github.com/seu-repositorio/etl-pipeline-logfire.git
   cd etl-pipeline-logfire
   ```

2. **Configurar o Ambiente**
   - Certifique-se de que o Python 3.8+ est√° instalado.
   - Crie e ative um ambiente virtual:
     ```bash
     python -m venv .venv
     source .venv/bin/activate  # No Windows: .venv\Scripts\activate
     ```

3. **Instalar as Depend√™ncias**
   - Instale as bibliotecas necess√°rias:
     ```bash
     pip install requests sqlalchemy logfire pydantic psycopg2
     ```

4. **Configurar o Banco PostgreSQL**
   - Configure a URI do PostgreSQL no arquivo:
     ```python
     POSTGRES_URI = "postgresql://<USUARIO>:<SENHA>@<HOST>:<PORTA>/<BANCO>"
     ```
   - Certifique-se de que o banco de dados est√° acess√≠vel e o usu√°rio tem permiss√µes para criar tabelas.

5. **Executar o Script**
   - Rode o script:
     ```bash
     python main.py
     ```

6. **Parar o Pipeline**
   - Use `Ctrl+C` para interromper a execu√ß√£o do pipeline.

---

## **Exemplo de Sa√≠da**

### **Logs no Console**
Voc√™ ver√° logs detalhados para cada etapa:
```plaintext
Conex√£o bem-sucedida com o banco PostgreSQL.
[Span] Fazendo a requisi√ß√£o para obter o valor do Bitcoin
[Span] Validando os dados com Pydantic
[Span] Carregando os dados no banco de dados PostgreSQL
[Dado inserido no banco: 97231.45 BTC/USD em 2024-12-01 10:30:15]
[Pipeline conclu√≠do. Aguardando 10 segundos antes de repetir.]
```

---

## **Benef√≠cios do Tracing e Logging**

1. **Monitoramento de Desempenho**:
   - Spans permitem identificar gargalos em cada etapa do pipeline.
   - Medi√ß√µes precisas do tempo de execu√ß√£o ajudam na otimiza√ß√£o.

2. **Visibilidade do Sistema**:
   - Logs enriquecidos fornecem informa√ß√µes contextuais sobre o estado do pipeline.
   - Possibilidade de correlacionar eventos entre diferentes sistemas.

3. **Facilidade de Depura√ß√£o**:
   - Mensagens detalhadas ajudam a diagnosticar problemas rapidamente.

4. **Manuten√ß√£o e Escalabilidade**:
   - Tracing oferece uma vis√£o clara do fluxo do sistema, facilitando a manuten√ß√£o e escalabilidade.

---

Com este projeto, voc√™ tem uma base robusta para monitorar e otimizar pipelines ETL, al√©m de integrar com ferramentas modernas de observabilidade como **Logfire**. üöÄ